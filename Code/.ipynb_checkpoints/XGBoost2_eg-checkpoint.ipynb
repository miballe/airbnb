{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost\n",
    "\n",
    "* Performs xgboost on training data. \n",
    "* Iterates over parameters with cross validation\n",
    "* Currently ignoring date parameters due to large number of factors. Waiting for preprocessing steps to improve. \n",
    "* Warning: takes a long time to cross validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Libraries\n",
    "library(xgboost)\n",
    "library(dplyr)\n",
    "library(Matrix)\n",
    "library(data.table)\n",
    "library(Ckmeans.1d.dp)\n",
    "library(e1071)\n",
    "library(caret)\n",
    "\n",
    "# Set Seed\n",
    "set.seed(1066)\n",
    "\n",
    "# Name of Run\n",
    "NAME <- \"eg_1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Currently remove date features because of large number of factors **  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read data\n",
    "# remove id and date_first_booking as they are not relevant\n",
    "# CURRENTLY REMOVES DATE PARAMETERS AS WELL\n",
    "dat_raw <- readRDS(\"../Data/users_PP.RDS\") %>%\n",
    "    na.omit()\n",
    "\n",
    "dat <- dat_raw %>%\n",
    "    select(-c(id,dataset,age_cln,age_cln2)) %>%\n",
    "    data.table(keep.rownames = F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# One-hot encoding  \n",
    "# https://cran.r-project.org/web/packages/xgboost/vignettes/discoverYourData.html\n",
    "sparse_dat <- sparse.model.matrix(country_destination ~ . -1, data = dat)\n",
    "\n",
    "# Find the training set\n",
    "sparse_tr <- sparse_dat[dat_raw$dataset == \"train\",]\n",
    "tr <- dat[dat_raw$dataset == \"train\",]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Parameter search using Cross validation\n",
    "# http://stats.stackexchange.com/questions/171043/how-to-tune-hyperparameters-of-xgboost-trees\n",
    "# Currently using low number of rounds to test\n",
    "\n",
    "# set up the cross-validated hyper-parameter search\n",
    "xgb_grid_1 = expand.grid(\n",
    "    nrounds = 10,                    # Iterations building each XGB model (100)\n",
    "    max_depth = c(2, 3, 4, 5),       # Maximum tree depth c(2, 4, 6, 8, 10)\n",
    "    eta = c(0.01, 0.005, 0.001),     # Learning rate c(0.01, 0.001, 0.0001)\n",
    "    gamma = 1,                       # Min loss reduction required to make a partition on leaf node [0:inf]\n",
    "    colsample_bytree = 0.3,          # proportion of features used in each tree c(0.3, 0.5, 0.7)\n",
    "    min_child_weight = 1\n",
    ")\n",
    "\n",
    "# trainControl creates settings for caret::train\n",
    "xgb_trcontrol_1 = trainControl(\n",
    "    method = \"cv\",          # Cross validation\n",
    "    number = 3,             # number of folds (5)\n",
    "    verboseIter = TRUE,\n",
    "    returnData = FALSE,\n",
    "    returnResamp = \"all\",   # How many summary stats to save # save losses across all models\n",
    "    allowParallel = TRUE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train XGboost\n",
    "# \"Kappa\" metric used for evaluation\n",
    "# xgb_train_1 = train(\n",
    "#     x = sparse_tr,\n",
    "#     y = tr$country_destination,\n",
    "#     trControl = xgb_trcontrol_1,\n",
    "#     tuneGrid = xgb_grid_1,\n",
    "#     method = \"xgbTree\", \n",
    "#     metric = \"Kappa\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.464063\n",
      "[1]\ttrain-merror:0.459373\n",
      "[2]\ttrain-merror:0.454256\n",
      "[3]\ttrain-merror:0.451848\n",
      "[4]\ttrain-merror:0.449214\n",
      "[5]\ttrain-merror:0.448111\n",
      "[6]\ttrain-merror:0.447270\n",
      "[7]\ttrain-merror:0.446568\n",
      "[8]\ttrain-merror:0.446041\n",
      "[9]\ttrain-merror:0.445189\n",
      "[10]\ttrain-merror:0.444449\n",
      "[11]\ttrain-merror:0.443721\n",
      "[12]\ttrain-merror:0.443521\n",
      "[13]\ttrain-merror:0.442567\n",
      "[14]\ttrain-merror:0.442179\n",
      "[15]\ttrain-merror:0.440661\n",
      "[16]\ttrain-merror:0.439921\n",
      "[17]\ttrain-merror:0.439056\n",
      "[18]\ttrain-merror:0.438855\n",
      "[19]\ttrain-merror:0.437864\n",
      "[20]\ttrain-merror:0.437476\n",
      "[21]\ttrain-merror:0.436711\n",
      "[22]\ttrain-merror:0.435971\n",
      "[23]\ttrain-merror:0.435770\n",
      "[24]\ttrain-merror:0.435168\n"
     ]
    }
   ],
   "source": [
    "xgb <- xgboost(data = sparse_tr, \n",
    "               label = as.numeric(tr$country_destination) - 1, \n",
    "               eta = 0.1,\n",
    "               max_depth = 9, \n",
    "               nround=25, \n",
    "               subsample = 0.5,\n",
    "               colsample_bytree = 0.5,\n",
    "               eval_metric = \"merror\",\n",
    "               objective = \"multi:softprob\",\n",
    "               num_class = 12,\n",
    "               nthread = 3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "saveRDS(xgb, paste0(\"./Models/xgb_model\", NAME, \".RDS\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Evaluating importance of features to the model\n",
    "# importance <- xgb.importance(sparse_tr@Dimnames[[2]], \n",
    "#                              #model = xgb$finalModel, \n",
    "#                              model = xgb,\n",
    "#                              data = sparse_tr, \n",
    "#                              label = as.numeric(tr$country_destination)\n",
    "#                             )\n",
    "# xgb.plot.importance(importance_matrix = importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# str(xgb$finalModel)\n",
    "# xgb$results$Kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# scatter plot of the Kappa against max_depth and eta\n",
    "# ggplot(xgb$results, aes(x = as.factor(eta), y = max_depth, size = Kappa, color = Kappa)) + \n",
    "#    geom_point() + \n",
    "#    theme_bw() + \n",
    "#    scale_size_continuous(guide = \"none\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions\n",
    "We use the \"predictions\" function to evaluate our model on both the training set and set set. We see from the below that the probabilities lead to NDF and US always being predicted. The accuracy at this point is also quite low. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset <- dat_raw$dataset\n",
    "target <- dat$country_destination\n",
    "# save(xgb, sparse_dat, dataset, target, file = \"test.RData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " logi [1:133869] TRUE TRUE TRUE TRUE FALSE TRUE ...\n",
      "NULL\n",
      "   AU    CA    DE    ES    FR    GB    IT   NDF    NL other    PT    US \n",
      "  279   657   535  1069  2267  1104  1241 37778   373  4632   102 29700 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       ".\n",
       "  NDF other    US \n",
       "48703     1 31033 "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "0.56483188482135"
      ],
      "text/latex": [
       "0.56483188482135"
      ],
      "text/markdown": [
       "0.56483188482135"
      ],
      "text/plain": [
       "[1] 0.5648319"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       ".\n",
       "  NDF    US \n",
       "16064 10301 "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "0.540489285036981"
      ],
      "text/latex": [
       "0.540489285036981"
      ],
      "text/markdown": [
       "0.540489285036981"
      ],
      "text/plain": [
       "[1] 0.5404893"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source(\"Predictions.R\")\n",
    "# pred <- predictions(xgb$finalModel, sparse_dat, dat_raw$dataset, dat$country_destination)\n",
    "pred <- predictions(xgb, sparse_dat, dat_raw$dataset, dat$country_destination)\n",
    "\n",
    "pred$pred_tr %>% table()\n",
    "pred$acc_tr\n",
    "\n",
    "pred$pred_ts %>% table()\n",
    "pred$acc_ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "https://www.kaggle.com/indradenbakker/airbnb-recruiting-new-user-bookings/rscript-0-86547/discussion  \n",
    "As per the example script above this submission file currently just takes the top 5 predictions in order as its submission file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formal class 'dgCMatrix' [package \"Matrix\"] with 6 slots\n",
      "  ..@ i       : int [1:3448523] 0 1 2 3 4 5 6 7 8 9 ...\n",
      "  ..@ p       : int [1:166] 0 133869 133874 134989 136694 148427 179555 209911 229539 241537 ...\n",
      "  ..@ Dim     : int [1:2] 133869 165\n",
      "  ..@ Dimnames:List of 2\n",
      "  .. ..$ : chr [1:133869] \"1\" \"2\" \"3\" \"4\" ...\n",
      "  .. ..$ : chr [1:165] \"X\" \"age_bucket0-4\" \"age_bucket100+\" \"age_bucket15-19\" ...\n",
      "  ..@ x       : num [1:3448523] 2 3 4 7 8 9 11 12 14 15 ...\n",
      "  ..@ factors : list()\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions on competition test set. \n",
    "# compare prediction to results\n",
    "source(\"Generate_submission.R\")\n",
    "sparse_test <- sparse_dat[dat_raw$set == \"test_external\",]\n",
    "id <- as.character(dat_raw[dat_raw$dataset == \"test_external\", \"id\"])\n",
    "\n",
    "str(sparse_test)\n",
    "#final <- submission(xgb$finalModel, sparse_test, id, paste0(\"xgb\", NAME))\n",
    "final <- submission(xgb, sparse_test, id, paste0(\"xgb\", NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in str(final): object 'final' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in str(final): object 'final' not found\n"
     ]
    }
   ],
   "source": [
    "#name <- paste0(\"xgb_\", NAME)\n",
    "#save(xgb, sparse_test, id, name, file = \"test.RData\")\n",
    "\n",
    "str(final)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

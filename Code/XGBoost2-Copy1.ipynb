{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost\n",
    "\n",
    "* Performs xgboost on training data. \n",
    "* Iterates over parameters with cross validation\n",
    "* Currently ignoring date parameters due to large number of factors. Waiting for preprocessing steps to improve. \n",
    "* Warning: takes a long time to cross validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Attaching package: 'dplyr'\n",
      "\n",
      "The following object is masked from 'package:xgboost':\n",
      "\n",
      "    slice\n",
      "\n",
      "The following objects are masked from 'package:stats':\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "The following objects are masked from 'package:base':\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "\n",
      "Attaching package: 'data.table'\n",
      "\n",
      "The following objects are masked from 'package:dplyr':\n",
      "\n",
      "    between, last\n",
      "\n",
      "Loading required package: lattice\n",
      "Loading required package: ggplot2\n"
     ]
    }
   ],
   "source": [
    "# Libraries\n",
    "library(xgboost)\n",
    "library(dplyr)\n",
    "library(Matrix)\n",
    "library(data.table)\n",
    "library(Ckmeans.1d.dp)\n",
    "library(e1071)\n",
    "library(caret)\n",
    "\n",
    "# Set Seed\n",
    "set.seed(1066)\n",
    "\n",
    "NAME <- \"eg_1\" # Name of Run (used for save file names)\n",
    "DATAPATH <- \"../Data/users_PP.RDS\" # Path to preprocessed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Currently remove date features because of large number of factors **  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read data\n",
    "# remove id and date_first_booking as they are not relevant\n",
    "# CURRENTLY REMOVES DATE PARAMETERS AS WELL\n",
    "dat_raw <- readRDS(DATAPATH) %>%\n",
    "    na.omit()\n",
    "\n",
    "# Remove unwanted features\n",
    "features_rm <- colnames(dat_raw) %in% c(\"id\", \"dataset\", \"first_browser\", \"age_cln\", \"age_cln2\", \"date_first_booking\", \"X\")\n",
    "dat <- dat_raw[, !features_rm] %>%\n",
    "    data.table(keep.rownames = F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# One-hot encoding  \n",
    "# https://cran.r-project.org/web/packages/xgboost/vignettes/discoverYourData.html\n",
    "sparse_dat <- sparse.model.matrix(country_destination ~ . -1, data = dat)\n",
    "\n",
    "# Find the training set\n",
    "sparse_tr <- sparse_dat[dat_raw$dataset == \"train\",]\n",
    "tr <- dat[dat_raw$dataset == \"train\",]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in data.frame(..., check.names = FALSE): arguments imply differing number of rows: 29, 133869\n",
     "output_type": "error",
     "traceback": [
      "Error in data.frame(..., check.names = FALSE): arguments imply differing number of rows: 29, 133869\n"
     ]
    }
   ],
   "source": [
    "# One hot with data frames instead\n",
    "df_all <- dat\n",
    "# one-hot-encoding features\n",
    "ohe_feats = c('gender', 'signup_method', 'signup_flow', 'language', 'affiliate_channel', 'affiliate_provider', 'first_affiliate_tracked', 'signup_app', 'first_device_type', 'first_browser')\n",
    "dummies <- dummyVars(~ gender + signup_method + signup_flow + language + affiliate_channel + affiliate_provider + \n",
    "                     first_affiliate_tracked + signup_app + first_device_type, data = df_all)\n",
    "df_all_ohe <- as.data.frame(predict(dummies, newdata = df_all))\n",
    "df_all_combined <- cbind(df_all[,(colnames(df_all) %in% ohe_feats)], df_all_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes 'data.table' and 'data.frame':\t133869 obs. of  29 variables:\n",
      " $ age_bucket             : Factor w/ 20 levels \"0-4\",\"100+\",\"15-19\",..: 7 12 8 9 9 11 7 9 7 7 ...\n",
      " $ dac_year               : int  2011 2010 2011 2010 2010 2010 2010 2010 2010 2010 ...\n",
      " $ dac_month              : int  5 9 12 1 1 1 1 1 1 1 ...\n",
      " $ dac_day                : int  25 28 5 2 3 4 4 5 5 7 ...\n",
      " $ dac_week               : int  21 39 49 0 1 1 1 1 1 1 ...\n",
      " $ dac_yearweek           : int  201121 201039 201149 201000 201001 201001 201001 201001 201001 201001 ...\n",
      " $ dac_yearmonth          : int  201105 201009 201112 201001 201001 201001 201001 201001 201001 201001 ...\n",
      " $ dac_yearmonthday       : int  20110525 20100928 20111205 20100102 20100103 20100104 20100104 20100105 20100105 20100107 ...\n",
      " $ dac_yearmonthweek      : int  20110521 20100939 20111249 20100100 20100101 20100101 20100101 20100101 20100101 20100101 ...\n",
      " $ tfa_year               : int  2009 2009 2009 2010 2010 2010 2010 2010 2010 2010 ...\n",
      " $ tfa_month              : int  5 6 10 1 1 1 1 1 1 1 ...\n",
      " $ tfa_day                : int  23 9 31 2 3 4 4 5 5 7 ...\n",
      " $ tfa_week               : int  20 23 43 0 1 1 1 1 1 1 ...\n",
      " $ tfa_yearweek           : int  200920 200923 200943 201000 201001 201001 201001 201001 201001 201001 ...\n",
      " $ tfa_yearmonth          : int  200905 200906 200910 201001 201001 201001 201001 201001 201001 201001 ...\n",
      " $ tfa_yearmonthday       : int  20090523 20090609 20091031 20100102 20100103 20100104 20100104 20100105 20100105 20100107 ...\n",
      " $ tfa_yearmonthweek      : int  20090520 20090623 20091043 20100100 20100101 20100101 20100101 20100101 20100101 20100101 ...\n",
      " $ lag                    : int  732 476 765 0 0 0 0 0 0 0 ...\n",
      " $ NAs_profile            : int  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ gender                 : Factor w/ 3 levels \"FEMALE\",\"MALE\",..: 2 1 1 1 1 1 1 1 1 1 ...\n",
      " $ signup_method          : Factor w/ 4 levels \"basic\",\"facebook\",..: 2 1 2 1 1 1 1 1 1 1 ...\n",
      " $ signup_flow            : int  0 3 0 0 0 0 0 0 0 0 ...\n",
      " $ language               : Factor w/ 26 levels \"-unknown-\",\"ca\",..: 7 7 7 7 7 7 7 7 7 7 ...\n",
      " $ affiliate_channel      : Factor w/ 8 levels \"api\",\"content\",..: 8 3 3 4 3 4 4 4 4 4 ...\n",
      " $ affiliate_provider     : Factor w/ 18 levels \"baidu\",\"bing\",..: 9 5 5 3 5 3 3 3 3 3 ...\n",
      " $ first_affiliate_tracked: Factor w/ 7 levels \"linked\",\"local ops\",..: 7 7 7 7 4 7 7 7 1 7 ...\n",
      " $ signup_app             : Factor w/ 4 levels \"Android\",\"iOS\",..: 4 4 4 4 4 4 4 4 4 4 ...\n",
      " $ first_device_type      : Factor w/ 9 levels \"Android Phone\",..: 6 9 6 6 6 6 6 5 6 5 ...\n",
      " $ country_destination    : Factor w/ 12 levels \"AU\",\"CA\",\"DE\",..: 8 12 10 12 12 12 12 8 8 8 ...\n",
      " - attr(*, \".internal.selfref\")=<externalptr> \n"
     ]
    }
   ],
   "source": [
    "ii <- colnames(df_all) %in% ohe_feats\n",
    "str(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train xgboost with specific settings\n",
    "model <- xgboost(data = sparse_tr, \n",
    "               label = as.numeric(tr$country_destination) - 1, \n",
    "               eta = 0.1,\n",
    "               max_depth = 9, \n",
    "               nround=25, \n",
    "               subsample = 0.5,\n",
    "               colsample_bytree = 0.5,\n",
    "               eval_metric = \"merror\",\n",
    "               objective = \"multi:softprob\",\n",
    "               num_class = 12,\n",
    "               nthread = 3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Parameter search using Cross validation\n",
    "# http://stats.stackexchange.com/questions/171043/how-to-tune-hyperparameters-of-xgboost-trees\n",
    "# Currently using low number of rounds to test\n",
    "\n",
    "# set up the cross-validated hyper-parameter search\n",
    "xgb_grid_1 = expand.grid(\n",
    "    nrounds = 10,                    # Iterations building each XGB model (100)\n",
    "    max_depth = c(2, 3, 4, 5),       # Maximum tree depth c(2, 4, 6, 8, 10)\n",
    "    eta = c(0.01, 0.005, 0.001),     # Learning rate c(0.01, 0.001, 0.0001)\n",
    "    gamma = 1,                       # Min loss reduction required to make a partition on leaf node [0:inf]\n",
    "    colsample_bytree = 0.3,          # proportion of features used in each tree c(0.3, 0.5, 0.7)\n",
    "    min_child_weight = 1\n",
    ")\n",
    "\n",
    "# trainControl creates settings for caret::train\n",
    "xgb_trcontrol_1 = trainControl(\n",
    "    method = \"cv\",          # Cross validation\n",
    "    number = 3,             # number of folds (5)\n",
    "    verboseIter = TRUE,\n",
    "    returnData = FALSE,\n",
    "    returnResamp = \"all\",   # How many summary stats to save # save losses across all models\n",
    "    allowParallel = TRUE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train XGboost\n",
    "# \"Kappa\" metric used for evaluation\n",
    "xgb_train_1 = train(\n",
    "    x = sparse_tr,\n",
    "    y = tr$country_destination,\n",
    "    trControl = xgb_trcontrol_1,\n",
    "    tuneGrid = xgb_grid_1,\n",
    "    method = \"xgbTree\", \n",
    "    metric = \"Kappa\"\n",
    ")\n",
    "\n",
    "saveRDS(xgb_train_1, paste0(\"./Models/\", NAME, \".RDS\"))\n",
    "model <- xgb_train_1$finalModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plots performance metrics if caret was used \n",
    "if(!is.null(xgb_train_1$results)){\n",
    "\n",
    "# Evaluating importance of features to the model\n",
    "importance <- xgb.importance(sparse_tr@Dimnames[[2]], \n",
    "                             model = model, \n",
    "                             data = sparse_tr, \n",
    "                             label = as.numeric(tr$country_destination)\n",
    "                            )\n",
    "xgb.plot.importance(importance_matrix = head(importance,30))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if(!is.null(xgb_train_1$results)){\n",
    "    # scatter plot of the Kappa against max_depth and eta\n",
    "    ggplot(xgb_train_1$results, aes(x = as.factor(eta), y = max_depth, size = Kappa, color = Kappa)) + \n",
    "        geom_point() + \n",
    "        theme_bw() + \n",
    "        scale_size_continuous(guide = \"none\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions\n",
    "We use the \"predictions\" function to evaluate our model on both the training set and set set. We see from the below that the probabilities lead to NDF and US always being predicted. The accuracy at this point is also quite low. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "source(\"Predictions.R\")\n",
    "pred <- predictions(model, sparse_dat, dat_raw$dataset, dat$country_destination)\n",
    "\n",
    "pred$pred_tr %>% table()\n",
    "pred$acc_tr\n",
    "\n",
    "pred$pred_ts %>% table()\n",
    "pred$acc_ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "https://www.kaggle.com/indradenbakker/airbnb-recruiting-new-user-bookings/rscript-0-86547/discussion  \n",
    "As per the example script above this submission file currently just takes the top 5 predictions in order as its submission file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate predictions on competition test set. \n",
    "# compare prediction to results\n",
    "source(\"Generate_submission.R\")\n",
    "sparse_test <- sparse_dat[dat_raw$dataset == \"test_external\",]\n",
    "id <- dat_raw[dat_raw$dataset == \"test_external\", \"id\"]\n",
    "final <- submission(model, sparse_test, id, NAME)\n",
    "\n",
    "head(final$df,20)\n",
    "head(final$file,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save(model, sparse_dat, dat_raw, dat, file = \"test.RData\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
